{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738a9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, f1_score, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046444e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a990b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dataset = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\", usecols=[0, 1], names=['Spam', 'Text'],\n",
    "                           skiprows=1)\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4272e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncation(text):\n",
    "    cleaned = ''.join([word for word in text if word not in string.punctuation])\n",
    "    return cleaned\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(lambda x: remove_puncation(x))\n",
    "\n",
    "def tokenize(text):\n",
    "\n",
    "    # Usunięcie wielkich liter\n",
    "    clean_text = text.lower()\n",
    "\n",
    "    # Tokenizacja\n",
    "    tokenized_text = nltk.word_tokenize(clean_text)\n",
    "    return tokenized_text\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(lambda x: tokenize(x))\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    without_stopwords = [word for word in text if word not in stopwords]\n",
    "    return without_stopwords\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    return stemmed_words\n",
    "spam_dataset['Stemmed_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: stemming(x))\n",
    "\n",
    "lemmater = nltk.WordNetLemmatizer()\n",
    "def lemmatizing(text):\n",
    "    lemmatized_words = [lemmater.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23505013",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_spam = list(spam_dataset.loc[spam_dataset['Spam']==1, 'Lemmatized_Text'].values)\n",
    "words_spam = list(itertools.chain.from_iterable(words_spam))\n",
    "words_spam = ' '.join(words_spam)\n",
    "words_notspam = list(spam_dataset.loc[spam_dataset['Spam']==0, 'Lemmatized_Text'].values)\n",
    "words_notspam = list(itertools.chain.from_iterable(words_notspam))\n",
    "words_notspam = ' '.join(words_notspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afc2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dataframe = pd.DataFrame(columns = ['Model', 'F1_score', 'AUC'])\n",
    "metrics_dataframe\n",
    "models = []\n",
    "models_names = []\n",
    "predictions_proba_list = []\n",
    "\n",
    "def calculate_metrics(model, name, X_checked, y_checked):\n",
    "    models.append(model)\n",
    "    models_names.append(name)\n",
    "    global metrics_dataframe\n",
    "    predictions = model.predict(X_checked)\n",
    "    predictions_proba = model.predict_proba(X_checked)\n",
    "    predictions_proba_list.append(predictions_proba[:,1])\n",
    "\n",
    "    ############## metryki dla sprawdzanego modelu ################\n",
    "\n",
    "    # Precision, Recall, F1, Accuracy\n",
    "    print(classification_report(y_checked, predictions))\n",
    "\n",
    "    # Confusion matrix\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(y_checked, predictions)\n",
    "    ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='.0f')\n",
    "    ax.set_title('Confusion Matrix\\n\\n')\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ')\n",
    "    plt.show()\n",
    "\n",
    "    # plot ROC curve\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    for model_selected, name_selected, pred_proba in zip(models, models_names, predictions_proba_list):\n",
    "        fpr, tpr, thresholds = roc_curve(y_checked, pred_proba)\n",
    "        plt.plot(fpr, tpr, label=name_selected)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    f1_metric = f1_score(y_checked, predictions)\n",
    "    auc_metric = roc_auc_score(y_checked, predictions_proba[:,1])\n",
    "    metrics_dataframe = metrics_dataframe.append({'Model': name, 'F1_score': f1_metric, 'AUC': auc_metric},\n",
    "                                                 ignore_index=True)\n",
    "    return metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf06c81",
   "metadata": {},
   "source": [
    "# ZAMIANA TEKSTU W WEKTOR (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e1596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x))\n",
    "y = spam_dataset['Spam']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c2224ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_forest = vectorizer.fit_transform(X_train)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "forest = forest.fit(X_train_forest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82bac30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7573"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e4ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7573"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.feature_importances_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52d289c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       008704050406\n",
       "1             0089my\n",
       "2               0121\n",
       "3        01223585236\n",
       "4        01223585334\n",
       "            ...     \n",
       "7568             ûªt\n",
       "7569            ûªve\n",
       "7570              ûï\n",
       "7571         ûïharry\n",
       "7572              ûò\n",
       "Name: Feature_names, Length: 7573, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df = pd.DataFrame({'Feature_names':feature_names, 'Importances': forest.feature_importances_})\n",
    "df_imp = df[df[\"Importances\"] > 0.001]\n",
    "feature = df['Feature_names']\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec747167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4747    beauty life next second hide thousand secret w...\n",
       "5295                                    alex say he ok ok\n",
       "5568                          ì b going esplanade fr home\n",
       "4654    prasanth ettans mother passed away last night ...\n",
       "1133    entered cabin pa said happy bday bos felt spec...\n",
       "                              ...                        \n",
       "2329            surfing online store offer want buy thing\n",
       "1932                            jus finished avatar nigro\n",
       "5316                             jus finish watching tv u\n",
       "3215    urgent trying contact u today draw show å£2000...\n",
       "763     nothing jus tot u would ask co u ba gua went m...\n",
       "Name: Lemmatized_Text, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedf62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "bow_df = pd.DataFrame(\n",
    "    X_counts.toarray(), columns=feature_names, index=X_train\n",
    ")\n",
    "X_imp = bow_df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b8cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Wybrane hiperparametry:  {'model__max_depth': 20, 'model__min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = Pipeline(steps=[('model', RandomForestClassifier(n_estimators=1000, n_jobs=-1))])\n",
    "\n",
    "params = {'model__max_depth': [3, 5, 10, 20],\n",
    "          'model__min_samples_leaf': [3, 5, 10, 15]}\n",
    "\n",
    "grid_search = GridSearchCV(model_pipeline, params, cv=5, n_jobs=-1, verbose=10, scoring='f1_macro')\n",
    "\n",
    "grid_search.fit(X_imp, y_train)\n",
    "\n",
    "print('Wybrane hiperparametry: ', grid_search.best_params_)\n",
    "model_pipeline_v1 = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1137b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393, 3821)\n",
      "(1393, 3821)\n",
      "(1393,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3722                                 left already orchard\n",
       "3062    hi babe jordan r u im home abroad lonely text ...\n",
       "472     nothing meant money enters account bank remove...\n",
       "4829    word checkmate chess come persian phrase shah ...\n",
       "5371                                lol oh got friend dog\n",
       "                              ...                        \n",
       "2412    dont know u u dont know send chat 86688 let fi...\n",
       "2326    xmas story peace xmas msg love xmas miracle je...\n",
       "1224    winner u specially selected 2 receive å£1000 c...\n",
       "3148                         sorry meeting ill call later\n",
       "1481                            im guy browsin compulsory\n",
       "Name: Lemmatized_Text, Length: 1393, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts_test = vectorizer.fit_transform(X_test)\n",
    "#feature_names = vectorizer.get_feature_names_out()\n",
    "#print(feature_names.shape)\n",
    "print(X_counts_test.shape)\n",
    "print(X_counts_test.toarray().shape)\n",
    "print(X_test.shape)\n",
    "X_test.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "789825c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd1df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df_test = pd.DataFrame(\n",
    "    X_counts_test.toarray(), columns=feature_names, index=X_test.explode()\n",
    ")\n",
    "X_imp_test = bow_df_test[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e05f86b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.680809</td>\n",
       "      <td>0.171844</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.938061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.691939</td>\n",
       "      <td>0.149275</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.934470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.679478</td>\n",
       "      <td>0.154222</td>\n",
       "      <td>0.931900</td>\n",
       "      <td>0.934470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.463166</td>\n",
       "      <td>0.158978</td>\n",
       "      <td>0.913669</td>\n",
       "      <td>0.939910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.665741</td>\n",
       "      <td>0.155754</td>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.939013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  1.680809    0.171844    0.903226     0.938061\n",
       "1  1.691939    0.149275    0.935484     0.934470\n",
       "2  1.679478    0.154222    0.931900     0.934470\n",
       "3  1.463166    0.158978    0.913669     0.939910\n",
       "4  1.665741    0.155754    0.917266     0.939013"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "results = pd.DataFrame(cross_validate(model_pipeline_v1, X_imp_test, y_test, return_train_score=True))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c4f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
